version: "3.8"

# DEADMAN ULTIMATE SCRAPER - Docker Stack
# ========================================
# Usage:
#   docker compose up -d tor              # TOR only
#   docker compose up -d                  # TOR + Scraper
#   docker compose --profile storage up -d # Full stack with DB

services:
  # ============================================
  # TOR PROXY - Anonymous routing
  # ============================================
  tor:
    image: dperson/torproxy:latest
    container_name: deadman-tor
    restart: unless-stopped
    ports:
      - "9050:9050"   # SOCKS5 proxy
      - "9051:9051"   # Control port
    environment:
      - TOR_NewCircuitPeriod=300
      - TOR_MaxCircuitDirtiness=600
    networks:
      - scraper-net
    healthcheck:
      test: ["CMD-SHELL", "curl -s --socks5 localhost:9050 https://check.torproject.org/api/ip || exit 1"]
      interval: 60s
      timeout: 30s
      retries: 3

  # ============================================
  # SCRAPER - Python scraper worker
  # ============================================
  scraper:
    build: .
    container_name: deadman-scraper
    restart: unless-stopped
    depends_on:
      tor:
        condition: service_healthy
    environment:
      - TOR_SOCKS_HOST=tor
      - TOR_SOCKS_PORT=9050
      - TOR_CONTROL_PORT=9051
      - TOR_METHOD=docker
      - PYTHONUNBUFFERED=1
    volumes:
      - ./data:/app/data
      - ./config:/app/config
      - ./output:/app/output
    networks:
      - scraper-net

  # ============================================
  # FLARESOLVERR - Cloudflare bypass
  # ============================================
  flaresolverr:
    image: ghcr.io/flaresolverr/flaresolverr:latest
    container_name: deadman-flaresolverr
    restart: unless-stopped
    ports:
      - "8191:8191"
    environment:
      - LOG_LEVEL=info
    networks:
      - scraper-net
    profiles:
      - bypass

  # ============================================
  # MONGODB - Data persistence (optional)
  # ============================================
  mongo:
    image: mongo:7
    container_name: deadman-mongo
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
      - ./docker/mongo-init.js:/docker-entrypoint-initdb.d/init.js:ro
    environment:
      - MONGO_INITDB_DATABASE=deadman
    networks:
      - scraper-net
    profiles:
      - storage

  # ============================================
  # ELASTICSEARCH - Search & analytics (optional)
  # ============================================
  elasticsearch:
    image: elasticsearch:8.12.0
    container_name: deadman-elastic
    restart: unless-stopped
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elastic-data:/usr/share/elasticsearch/data
    networks:
      - scraper-net
    profiles:
      - storage

  # ============================================
  # REDIS - Caching (optional)
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: deadman-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - scraper-net
    profiles:
      - storage

networks:
  scraper-net:
    driver: bridge

volumes:
  mongo-data:
  elastic-data:
  redis-data:
